{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d5364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input data is in minute intervals, and the model is trained to predict\n",
    "# the total real power consumption for a single minute based on the input \n",
    "# features, so the predicted value represents the predicted total real power\n",
    "# consumption in kilowatts for a single minute.\n",
    "# It's worth noting that the power consumption of a household \n",
    "# can vary widely over time, and is influenced by many factors, \n",
    "# such as the time of day, day of the week, season, and weather. \n",
    "# So the accuracy of the predictions may be limited by the amount of data \n",
    "# available and the complexity of the model.\n",
    "\n",
    "# Also, it's important to consider that the power consumption of a household \n",
    "# may not always directly translate to the cost of electricity in NOK, \n",
    "# as the price of electricity can vary depending on the time of day, \n",
    "# the day of the week, and other factors such as taxes and subsidies. \n",
    "# So it's important to take these factors into account when interpreting \n",
    "# the predictions and calculating the cost of electricity.\n",
    "\n",
    "#Example:\n",
    "\n",
    "#predicted_price = predicted_power_consumption * price_per_kwh\n",
    "\n",
    "#predicted_price = 0.438 kW * 1.50 NOK/kWh = 0.657 NOK\n",
    "\n",
    "#The model predicts kW based on minute intervals,\n",
    "#so the predicted cost for 1 min with here was 0.657.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf8a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports for the project.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ef40f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('household_power_consumption.txt', delimiter=';', parse_dates=True, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786d593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf4b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tqdm to add a progress bar to the apply method\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295592be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with missing values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6026e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date and time columns to a single datetime column\n",
    "df['datetime'] = df.progress_apply(lambda row: pd.to_datetime(row['Date'] + ' ' + row['Time']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3483ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original date and time columns\n",
    "df.drop(['Date', 'Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the datetime column as the index\n",
    "df.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bec57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aacb256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a target column for the next day's global_active_power value\n",
    "df['target'] = df['Global_active_power'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c58ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the last row, which has a NaN value for the target\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bf8804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'target' column and fit the MinMaxScaler to the remaining feature data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df.drop('target', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a2fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and labels\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c16ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new row of feature data to predict the next day's electricity price\n",
    "new_data = np.array([[0.5, 0.3, 0.2, 0.4, 0.5, 0.6, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b122b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the number of columns in the input data matches the number of columns in the data used to fit the scaler\n",
    "if new_data.shape[1] != scaler.data_max_.shape[0]:\n",
    "    raise ValueError(f\"Expected {scaler.data_max_.shape[0]} features, but got {new_data.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee10432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b6c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the new data using the same MinMaxScaler object used to preprocess the dataset\n",
    "new_data = scaler.transform(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fab9ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction using the model\n",
    "prediction = model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc52f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data_min and data_max arrays to match the shape of new_data\n",
    "data_min = scaler.data_min_.reshape(1, -1)\n",
    "data_max = scaler.data_max_.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e155789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the predicted value back to the original range using the inverse_transform method\n",
    "prediction_unscaled = (prediction * (data_max - data_min)) + data_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4648db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the unscaled predicted value from the array\n",
    "unscaled_target = prediction_unscaled[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3645aa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the predicted electricity price in the original units\n",
    "print(prediction_unscaled)\n",
    "\n",
    "# Print the predicted electricity price\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9640066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(model, 'model.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
